<html>
<body>

<center>

<h1>CS 205 Project <br /> Online Document Aligner </h1>
<h2>By Edouard Godfrey and Lars Kristian Johansen </h2>
</center>
<h3>Introduction</h3>
<p>
Our objective is to design a program that can match incoming english newswire to other newswire in a
foreign language. The translation offered by Google on specific events in the news is not of high quality
due to broad and changing vocabulary in this kind of corpus. Instead of having a statistical system
translating every sentence of the source document, our approach tries to find a corresponding newswire
on the same topic in another language.<br />
We present here the different steps that we plan to go through to obtain a satisfying result. We try
to design here a simple model that can allow fast computation and usage of parallelism. The accent here
is to build a viable system that can work online on two incoming data flux corresponding to newswire
in the two languages.

</p>
<h3>Collecting Data</h3>
<p>
We will start by crawling a website or a search engine to gather newswire in both languages. These
data will be cleaned to remove any html formatting such that they will appear as a continuous text. To
simulate the online process, we will aggregate these wires in two queues, one for each language. Our
application will work directly by reading in these queues.

</p>
<h3>Translation</h3>
<p>
We will work in one of the two languages. Therefore, we distinguish between a source and a target
language. The documents in the source language are translated using a simple bilingual lexicon while
documents in the target language are not modified.

</p>
<h3>Online LDA</h3>
<p>
To measure the similarity between documents, we will use Latent Dirichlet Allocation (LDA) to identify
the topics in each newswire. With this model, every document is considered as a bag of words. The
order does not matter.<br />
Since we are working on an online system, we will continue to add incoming documents to the current
set of documents. We can make the size of this set of documents constant by removing the most ancient
document.<br />
The overall topic model is retrained during several iterations. Finally, the topic distribution of the
current document is compared to the distribution of the documents in the other language. The couple
that achieves the least Kullback-Leibler divergence is selected as a matching couple.

</p>
<h3>Parallelism</h3>
<p>
Because the goal is having a viable product working online with incoming flux, time processing is key
in our system. Several parts can be implemented in parallel to provide good performances. The part
of translation with lookups in a bilingual lexicon is embarrassingly parallel. The LDA Model can be
retrained with parallel Gibbs Sampling.

</p>
<h3>Last words</h3>
<p>
Our main focus will be on the parallelization of LDA algorihm, since this is the one that are not trivial
and therefore of biggest interest. We plan to start focusing on LDA first, and then implementing the
complete application after that.
</p>

<p>Document in <a href="project.pdf">pdf</a> or back to <a href="index.html">frontpage</a>.

</body>
</html>


